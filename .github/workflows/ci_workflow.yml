name: Model CI - Training, Artifact Storage, and Docker Push (Final)

on:
  push:
    branches:
      - main
    paths:
      - "MLProject_folder/**"
  workflow_dispatch:

jobs:
  train-and-build-docker:
    runs-on: ubuntu-latest

    steps:
      - name: 1. Checkout Repository
        uses: actions/checkout@v4

      - name: 2. Set up Conda Environment
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: "3.12"
          create-environment-file: MLProject_folder/conda.yaml
          environment-file: MLProject_folder/conda.yaml
          activate-environment: mushroom-env

      - name: 3. Run Training Script
        id: training_step
        env:
          DAGSHUB_OWNER: ${{ secrets.DAGSHUB_OWNER }}
          DAGSHUB_REPO_NAME: ${{ secrets.DAGSHUB_REPO_NAME }}
          DAGSHUB_USER_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
          MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_OWNER }}
          MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}
        shell: bash -l {0}
        run: |
          echo "INFO: Running training script..."
          python MLProject_folder/modelling.py > modelling_log.txt
          echo "INFO: Training complete."

          # Get the Run ID from the log file and set it as a job output
          RUN_ID=$(grep 'MLflow Run ID:' modelling_log.txt | awk '{print $4}')
          echo "Extracted MLflow Run ID: $RUN_ID"
          echo "run_id=$RUN_ID" >> $GITHUB_OUTPUT

      - name: 4. Download Artifacts from DagsHub
        env:
          DAGSHUB_OWNER: ${{ secrets.DAGSHUB_OWNER }}
          DAGSHUB_REPO_NAME: ${{ secrets.DAGSHUB_REPO_NAME }}
        shell: bash -l {0}
        run: |
          pip install dagshub

          python -c "
          import mlflow
          import dagshub

          dagshub.init(repo_owner='${{ env.DAGSHUB_OWNER }}', repo_name='${{ env.DAGSHUB_REPO_NAME }}', mlflow=True)
          mlflow.artifacts.download_artifacts(
          run_id='${{ steps.training_step.outputs.run_id }}', 
          dst_path='./mlflow_artifacts'
          )
          print('✅ Artifacts downloaded successfully.')
          "

      - name: 5. Save MLflow artifacts to GitHub
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-run-artifacts
          path: ./mlflow_artifacts/

      - name: 6. Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: 7. Build and Push Docker Image
        shell: bash -l {0}
        run: |
          # The conda environment is still active, so mlflow is available.
          MODEL_URI="runs:/${{ steps.training_step.outputs.run_id }}/model"
          IMAGE_NAME="${{ secrets.DOCKERHUB_USERNAME }}/mushroom-classifier-msml:${{ github.sha }}"

          echo "INFO: Building Docker image from URI: $MODEL_URI"
          mlflow models build-docker --model-uri "$MODEL_URI" --name "$IMAGE_NAME" --enable-mlserver

          echo "INFO: Pushing image to Docker Hub..."
          docker push "$IMAGE_NAME"
          echo "✅ Docker image ${IMAGE_NAME} pushed successfully."
